{
    "batch_size": 64,
    "encode": "k-mer",
    "epochs": 100,
    "early_stop": 10,
    "lr": 0.001,
    "convolution_layers": {
        "n_layers": 4,
        "filters": [128, 60, 60, 120],
        "kernel_sizes": [7, 3, 5, 3]
    },
    "transformer_layers": {
        "n_layers": 0,
        "attn_key_dim": [16, 16, 16],
        "attn_heads": [2048, 2048, 2048]
    },
    "n_dense_layer": 1,
    "dense_neurons1": 64,
    "dropout_conv": "yes",
    "dropout_prob": 0.4,
    "pad": "same"
}
